# EmotionDetection
Humans are one of the most advanced species known. We communicate with each other
in ways more than just talking. We tend to display our emotional state through our body
language quite clearly most of the time. In years of research, it has come to notice that
humans have basic seven emotional states which they maintain. These states are neutral,
happiness, sadness, anger, disgust, fear, and surprise. Different models and methods
yield different accuracy and performance, partially depending on the data set used for
training and testing. To understand the process of emotion detection using facial
expressions extensive study needed to be done. Several papers which are based on
different methods and applied on different datasets are reviewed in this project. We
ourselves implemented few datasets on two different CNN models. The results of the
implementation have been compiled in the result analysis section. For CK+ dataset the
first model has performed significantly better that the second one. As for the FER2013
and Mixed dataset both the models have performed almost similarly giving an edge to
the first model. Overall, the first model generally performs better than the second one
across the evaluated datasets based on the F1 scores and accuracies. However, it's
important to consider other factors such as dataset characteristics, model architecture,
hyperparameters, and the specific emotion recognition task when interpreting these
results. The objective of this project was achieved successfully.
