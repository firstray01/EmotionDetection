{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCPDmbWGCA3U"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "import pandas as pd\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thh8my-OBtp7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv(r\"/content/drive/MyDrive/dataset/Mixed(kdef).csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmXJSDyVCTX8"
      },
      "outputs": [],
      "source": [
        "image_size = (48, 48)\n",
        "pixels = data['pixels'].tolist()\n",
        "images = np.array([np.array(pixels[i].split(' ')).astype('float32').reshape(48, 48) for i in range(len(pixels))])\n",
        "resized_images = np.array([resize(image, image_size, mode='reflect') for image in images])\n",
        "normalized_images = resized_images / 255.0\n",
        "labels = data['emotion'].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train = np_utils.to_categorical(np.array(y_train), num_classes)\n",
        "y_test = np_utils.to_categorical(np.array(y_test), num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWMWskSvCTg8"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers import concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDk-hbgsCTk7"
      },
      "outputs": [],
      "source": [
        "def ckextended_Model(input_shape=(48, 48, 1)):\n",
        "    # first input\n",
        "    model_visible = Input(shape=input_shape, name='input')\n",
        "    num_classes = 8\n",
        "\n",
        "    # the 1st block\n",
        "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name='conv1_1')(model_visible)\n",
        "    conv1_1 = BatchNormalization()(conv1_1)\n",
        "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
        "    conv1_2 = BatchNormalization()(conv1_2)\n",
        "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
        "    drop1_1 = Dropout(0.25, name = 'drop1_1')(pool1_1)\n",
        "\n",
        "    #the 2-nd block\n",
        "\n",
        "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name ='conv2_1')(drop1_1)\n",
        "    conv2_1 = BatchNormalization()(conv2_1)\n",
        "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
        "    conv2_2 = BatchNormalization()(conv2_2)\n",
        "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
        "    conv2_2 = BatchNormalization()(conv2_3)\n",
        "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
        "    drop2_1 = Dropout(0.35, name = 'drop2_1')(pool2_1)\n",
        "\n",
        "    #the 3-rd block\n",
        "\n",
        "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
        "    conv3_1 = BatchNormalization()(conv3_1)\n",
        "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
        "    conv3_2 = BatchNormalization()(conv3_2)\n",
        "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name ='conv3_3')(conv3_2)\n",
        "    conv3_3 = BatchNormalization()(conv3_3)\n",
        "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
        "    conv3_4 = BatchNormalization()(conv3_4)\n",
        "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
        "    drop3_1 = Dropout(0.45, name = 'drop3_1')(pool3_1)\n",
        "\n",
        "    #the 4-th block\n",
        "\n",
        "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
        "    conv4_1 = BatchNormalization()(conv4_1)\n",
        "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
        "    conv4_2 = BatchNormalization()(conv4_2)\n",
        "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
        "    conv4_3 = BatchNormalization()(conv4_3)\n",
        "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
        "    conv4_4 = BatchNormalization()(conv4_4)\n",
        "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
        "    drop4_1 = Dropout(0.55, name = 'drop4_1')(pool4_1)\n",
        "\n",
        "    #the 5-th block\n",
        "\n",
        "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
        "    conv5_1 = BatchNormalization()(conv5_1)\n",
        "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
        "    conv5_2 = BatchNormalization()(conv5_2)\n",
        "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
        "    conv5_4 = BatchNormalization()(conv5_4)\n",
        "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
        "    drop5_1 = Dropout(0.75, name = 'drop5_1')(pool5_1)\n",
        "\n",
        "    # Flatten and output\n",
        "    flatten = Flatten(name='flatten')(drop5_1)\n",
        "    output = Dense(num_classes, activation='softmax', name='output')(flatten)\n",
        "\n",
        "    # create model\n",
        "    model = Model(inputs=model_visible, outputs=output)\n",
        "\n",
        "    # summary layers\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tJaQChJCTn2"
      },
      "outputs": [],
      "source": [
        "model = ckextended_Model()\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "num_epochs = 100\n",
        "history = model.fit(X_train.reshape(-1, 48, 48, 1), y_train, batch_size=64, epochs=num_epochs, validation_data=(X_test.reshape(-1, 48, 48, 1), y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyMTvOmvCTpv"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_test.reshape(-1, 48, 48, 1), y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrdTg5ZdCTsj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training accuracy and loss\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "fig.set_size_inches(12, 4)\n",
        "\n",
        "ax[0].plot(history.history['accuracy'])\n",
        "ax[0].plot(history.history['val_accuracy'])\n",
        "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_title('Training Loss vs Validation Loss')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPcssIMmCTy_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        " # Make predictions on the test set\n",
        "y_pred_probs = model.predict(X_test.reshape(-1, 48, 48, 1))\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        " # Define class labels and emotions\n",
        "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral','contempt']\n",
        "emotions = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral','contempt']\n",
        " # Generate the confusion matrix\n",
        "confusion_mtx = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
        " # Plotting the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_mtx, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xticks(np.arange(len(class_labels)), class_labels)\n",
        "plt.yticks(np.arange(len(class_labels)), class_labels)\n",
        "plt.show()\n",
        " # Generate the classification report\n",
        "report = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=emotions)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}